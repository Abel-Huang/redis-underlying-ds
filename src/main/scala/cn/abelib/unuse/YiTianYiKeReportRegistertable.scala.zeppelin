/**
  * Created by Simon on 22/01/2017.
  */

import org.apache.spark.sql.SQLContext
import org.apache.spark.{SparkConf, SparkContext}
import org.joda.time.DateTime

val sc = new SparkContext(new SparkConf().setAppName("Simple Application").setMaster("local[4]"))
val sqlContext = SQLContext.getOrCreate(sc)


def getKey = (System.getenv("yitianyikeAk"), System.getenv("yitainyikeSk"))

val ak = getKey._1
val sk = getKey._2

// ------------------------------------

val bucket = "qiniu://fusionlog"

val now = new DateTime()
println("start at: ", now)

val daysago2 = now.plusDays(-3)

val domain = "7xna64.com2.z0.glb.qiniucdn.com"
val date = daysago2.toString("yyyy-MM-dd")
val h2 = daysago2.toString("HH")

val parquetUrl = s"qiniu://fusionlog/ytyk-parquet/${domain}/${date}/*"

sc.hadoopConfiguration.set("fs.qiniu.access.key", ak)
sc.hadoopConfiguration.set("fs.qiniu.secret.key", sk)
sc.hadoopConfiguration.set("fs.qiniu.bucket.domain", "http://fusionlog.qiniu.com")


// 注册主表，包含所有数据
sqlContext.read.parquet(parquetUrl).registerTempTable("ytyk")

